{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U torch torchvision;","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 0. Загружаем библиотеки, инициализируем случайные числа, задаем константы","metadata":{}},{"cell_type":"code","source":"import os\nfrom tqdm.autonotebook import tqdm, trange\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\n\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\n\nfrom sklearn.model_selection import train_test_split\nfrom pathlib import Path\nfrom torch.utils.data import DataLoader\n\nfrom torch.utils.data import Dataset\nfrom sklearn.preprocessing import LabelEncoder\nimport pickle\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2021-11-23T16:26:51.689832Z","iopub.execute_input":"2021-11-23T16:26:51.690178Z","iopub.status.idle":"2021-11-23T16:26:52.525594Z","shell.execute_reply.started":"2021-11-23T16:26:51.690126Z","shell.execute_reply":"2021-11-23T16:26:52.524534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random \nSEED = 7\n\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2021-11-23T16:26:54.335295Z","iopub.execute_input":"2021-11-23T16:26:54.336075Z","iopub.status.idle":"2021-11-23T16:26:54.34265Z","shell.execute_reply.started":"2021-11-23T16:26:54.336025Z","shell.execute_reply":"2021-11-23T16:26:54.341916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#работаю в kaggle ноутбуке\nTRAIN_DIR = Path('../input/journey-springfield/train')\nTEST_DIR = Path('../input/journey-springfield/testset')\nDATA_MODES = ['train', 'val', 'test']\nRESCALE_SIZE = 224\nDEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\nCUDA_LAUNCH_BLOCKING=1\nBATCH_SIZE=64 #при большем размере батча не хватает памяти\n\nprint(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T16:27:15.426478Z","iopub.execute_input":"2021-11-23T16:27:15.426748Z","iopub.status.idle":"2021-11-23T16:27:15.464339Z","shell.execute_reply.started":"2021-11-23T16:27:15.426718Z","shell.execute_reply":"2021-11-23T16:27:15.463229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Создаем класс для датасета. Добавила в него аугментации для режима 'train'.","metadata":{}},{"cell_type":"code","source":"class SimpsonsDataset(Dataset):\n\n    def __init__(self, files, mode):\n        super().__init__()\n        self.files = sorted(files)\n        self.mode = mode\n\n        if self.mode not in DATA_MODES:\n            print(f\"{self.mode} is not correct; correct modes: {DATA_MODES}\")\n            raise NameError\n\n        self.len_ = len(self.files)\n     \n        self.label_encoder = LabelEncoder()\n\n        if self.mode != 'test':\n            self.labels = [path.parent.name for path in self.files]\n            self.label_encoder.fit(self.labels)\n\n            with open('label_encoder.pkl', 'wb') as le_dump_file:\n                  pickle.dump(self.label_encoder, le_dump_file)\n                      \n    def __len__(self):\n        return self.len_\n      \n    def load_sample(self, file):\n        image = Image.open(file)\n        image.load()\n        return image\n  \n    def __getitem__(self, index):\n        transform = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n        ])\n        data_transforms = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n        #аугментации:\n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.RandomAutocontrast(p=0.5),\n        ])\n        \n        x = self.load_sample(self.files[index])\n        x = self._prepare_sample(x)\n        x = np.array(x / 255, dtype='float32')\n        if self.mode == 'train':\n          x = data_transforms(x)\n        else:\n          x = transform(x)\n        if self.mode == 'test':\n            return x\n        else:\n            label = self.labels[index]\n            label_id = self.label_encoder.transform([label])\n            y = label_id.item()\n            return x, y\n        \n    def _prepare_sample(self, image):\n        image = image.resize((RESCALE_SIZE, RESCALE_SIZE))\n        return np.array(image)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T16:27:17.983778Z","iopub.execute_input":"2021-11-23T16:27:17.984512Z","iopub.status.idle":"2021-11-23T16:27:17.997657Z","shell.execute_reply.started":"2021-11-23T16:27:17.984471Z","shell.execute_reply":"2021-11-23T16:27:17.9969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Загрузка данных. \nПроведена балансировка данных (код украден из комментов к задаче). В классах, в которых количество картинок меньше 100, картинки просто дублируются до 100. При этом аугментация должна помочь с переобучением.","metadata":{}},{"cell_type":"code","source":"train_val_files = sorted(list(TRAIN_DIR.rglob('*.jpg')))\ntest_files = sorted(list(TEST_DIR.rglob('*.jpg')))\n\nfrom sklearn.model_selection import train_test_split\n\ntrain_val_labels = [path.parent.name for path in train_val_files]\ntrain_files, val_files = train_test_split(train_val_files, test_size=0.25, \\\n                                          stratify=train_val_labels)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T16:27:21.261487Z","iopub.execute_input":"2021-11-23T16:27:21.262038Z","iopub.status.idle":"2021-11-23T16:27:22.468458Z","shell.execute_reply.started":"2021-11-23T16:27:21.261999Z","shell.execute_reply":"2021-11-23T16:27:22.467708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_classes = len(np.unique(train_val_labels))\nn_classes\n#42","metadata":{"execution":{"iopub.status.busy":"2021-11-23T16:27:24.295473Z","iopub.execute_input":"2021-11-23T16:27:24.295916Z","iopub.status.idle":"2021-11-23T16:27:24.316797Z","shell.execute_reply.started":"2021-11-23T16:27:24.295863Z","shell.execute_reply":"2021-11-23T16:27:24.316028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Балансировка классов\ntrain_labels = [path.parent.name for path in train_files]\nval_labels = [path.parent.name for path in val_files]     # классы val","metadata":{"execution":{"iopub.status.busy":"2021-11-23T16:27:26.431248Z","iopub.execute_input":"2021-11-23T16:27:26.431987Z","iopub.status.idle":"2021-11-23T16:27:26.478902Z","shell.execute_reply.started":"2021-11-23T16:27:26.431934Z","shell.execute_reply":"2021-11-23T16:27:26.478167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_dct_path_labels(train_files, train_labels):\n    dct_simpsons = {}\n    for label_i in np.unique(train_labels).tolist():\n        dct_simpsons[label_i] = []\n\n    for path_i, label_i in zip(train_files, train_labels):\n        dct_simpsons[label_i].append(path_i)\n\n    return dct_simpsons\n\ndef print_dct(dct_simpsons):\n    for key in dct_simpsons:\n        print(f\"{key}\\t{dct_simpsons[key]}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-23T16:27:27.616241Z","iopub.execute_input":"2021-11-23T16:27:27.617163Z","iopub.status.idle":"2021-11-23T16:27:27.624729Z","shell.execute_reply.started":"2021-11-23T16:27:27.617109Z","shell.execute_reply":"2021-11-23T16:27:27.623882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dct_path_train = create_dct_path_labels(train_files, train_labels)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T16:27:30.667439Z","iopub.execute_input":"2021-11-23T16:27:30.667963Z","iopub.status.idle":"2021-11-23T16:27:30.684958Z","shell.execute_reply.started":"2021-11-23T16:27:30.667925Z","shell.execute_reply":"2021-11-23T16:27:30.684134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for person in dct_path_train:\n    if len(dct_path_train[person]) < 100:\n        dct_path_train[person] = dct_path_train[person] * (100 // len(dct_path_train[person]))\n        dct_path_train[person].extend(dct_path_train[person][:100 - len(dct_path_train[person])])\n\nfor person in dct_path_train:\n    print(f\"{person}\\t{len(dct_path_train[person])}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-23T16:27:31.939646Z","iopub.execute_input":"2021-11-23T16:27:31.94022Z","iopub.status.idle":"2021-11-23T16:27:31.951126Z","shell.execute_reply.started":"2021-11-23T16:27:31.940179Z","shell.execute_reply":"2021-11-23T16:27:31.950335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_dct_from_labels(train_val_labels):\n\n    dct_simpsons = {}\n    for label_i in np.unique(train_val_labels).tolist():\n        dct_simpsons.update({label_i:train_val_labels.count(label_i)})\n\n    return dct_simpsons\n\nnew_train_files = []\n\nfor person in dct_path_train:\n    new_train_files.extend(dct_path_train[person])\n\nnew_train_label = [path.parent.name for path in new_train_files]","metadata":{"execution":{"iopub.status.busy":"2021-11-23T16:27:34.310726Z","iopub.execute_input":"2021-11-23T16:27:34.311088Z","iopub.status.idle":"2021-11-23T16:27:34.372757Z","shell.execute_reply.started":"2021-11-23T16:27:34.311047Z","shell.execute_reply":"2021-11-23T16:27:34.372037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_dataset = SimpsonsDataset(val_files, mode='val')\nnew_train_dataset = SimpsonsDataset(new_train_files, mode='train')","metadata":{"execution":{"iopub.status.busy":"2021-11-23T16:27:36.369293Z","iopub.execute_input":"2021-11-23T16:27:36.369599Z","iopub.status.idle":"2021-11-23T16:27:36.545849Z","shell.execute_reply.started":"2021-11-23T16:27:36.36957Z","shell.execute_reply":"2021-11-23T16:27:36.54511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Функции для обучения модели \n(оставлены без изменений)","metadata":{}},{"cell_type":"code","source":"def fit_epoch(model, train_dataloader, criterion, optimizer):\n    running_loss = 0.0\n    running_corrects = 0\n    processed_data = 0\n  \n    for inputs, labels in train_dataloader:\n        inputs = inputs.to(DEVICE) #перенос тензоров на видеокарту\n        labels = labels.to(DEVICE)\n        optimizer.zero_grad() #обнуляем градиенты, чтобы они не накапливались\n\n        outputs = model(inputs) #прогоняем данные из трейнлоадера чеез нашу сеть (модель). \n        loss = criterion(outputs, labels) #считаем лосс\n        loss.backward()\n        optimizer.step()\n        preds = torch.argmax(outputs, 1) #все, что больше 1, приводим к 1\n        running_loss += loss.item() * inputs.size(0) \n        running_corrects += torch.sum(preds == labels.data) #если предсказание совпадает с ответом, увеличиваем на 1 running_corrects\n        processed_data += inputs.size(0) \n              \n    train_loss = running_loss / processed_data #потери на трейне\n    train_acc = running_corrects.cpu().numpy() / processed_data #точность на трейне\n    return train_loss, train_acc","metadata":{"execution":{"iopub.status.busy":"2021-11-23T16:27:38.214718Z","iopub.execute_input":"2021-11-23T16:27:38.215306Z","iopub.status.idle":"2021-11-23T16:27:38.223623Z","shell.execute_reply.started":"2021-11-23T16:27:38.215262Z","shell.execute_reply":"2021-11-23T16:27:38.222806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_epoch(model, val_dataloader, criterion):\n    model.eval()\n    running_loss = 0.0\n    running_corrects = 0\n    processed_size = 0\n\n    for inputs, labels in val_dataloader:\n        inputs = inputs.to(DEVICE)\n        labels = labels.to(DEVICE)\n\n        with torch.set_grad_enabled(False):\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            preds = torch.argmax(outputs, 1)\n\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n        processed_size += inputs.size(0)\n    val_loss = running_loss / processed_size\n    val_acc = running_corrects.double() / processed_size\n    return val_loss, val_acc","metadata":{"execution":{"iopub.status.busy":"2021-11-23T16:27:40.089316Z","iopub.execute_input":"2021-11-23T16:27:40.089962Z","iopub.status.idle":"2021-11-23T16:27:40.09911Z","shell.execute_reply.started":"2021-11-23T16:27:40.089924Z","shell.execute_reply":"2021-11-23T16:27:40.098361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(train_files, val_files, model, epochs, batch_size):\n    train_dataloader = DataLoader(new_train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n    val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\n    history = []\n    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}\"\n\n    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n        opt = torch.optim.Adam(model.parameters(), lr=3e-4)\n        criterion = nn.CrossEntropyLoss()\n\n        for epoch in range(epochs):\n            train_loss, train_acc = fit_epoch(model, train_dataloader, criterion, opt)\n            print(\"loss\", train_loss)\n            \n            val_loss, val_acc = eval_epoch(model, val_dataloader, criterion)\n            history.append((train_loss, train_acc, val_loss, val_acc))\n            \n            pbar_outer.update(1)\n            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\\\n                                           v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))\n            \n    return history","metadata":{"execution":{"iopub.status.busy":"2021-11-23T16:27:42.009419Z","iopub.execute_input":"2021-11-23T16:27:42.01034Z","iopub.status.idle":"2021-11-23T16:27:42.022702Z","shell.execute_reply.started":"2021-11-23T16:27:42.01029Z","shell.execute_reply":"2021-11-23T16:27:42.021799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Transfer learning на сети EfficientNet","metadata":{}},{"cell_type":"code","source":"#в комментариях код для Inception\n#model = models.inception_v3(pretrained=True)\n!pip install efficientnet_pytorch","metadata":{"execution":{"iopub.status.busy":"2021-11-23T16:27:45.81706Z","iopub.execute_input":"2021-11-23T16:27:45.817788Z","iopub.status.idle":"2021-11-23T16:27:53.344608Z","shell.execute_reply.started":"2021-11-23T16:27:45.817749Z","shell.execute_reply":"2021-11-23T16:27:53.343765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from efficientnet_pytorch import EfficientNet\nmodel = EfficientNet.from_pretrained('efficientnet-b2')","metadata":{"execution":{"iopub.status.busy":"2021-11-23T16:27:56.623063Z","iopub.execute_input":"2021-11-23T16:27:56.623829Z","iopub.status.idle":"2021-11-23T16:27:56.817734Z","shell.execute_reply.started":"2021-11-23T16:27:56.62379Z","shell.execute_reply":"2021-11-23T16:27:56.81679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model._fc = nn.Linear(in_features=1408, out_features=n_classes, bias=True)\nmodel = model.to(DEVICE)\n\n#в комментариях код для Inception\n'''\nmodel.AuxLogits.fc = nn.Linear(768, n_classes)\nmodel.fc = nn.Linear(2048, n_classes)\n\nnum_features = 25088\nmodel.classifier = nn.Linear(num_features, n_classes)\n\nmodel = model.to(DEVICE)\n\nmodel.aux_logits = False\n'''","metadata":{"execution":{"iopub.status.busy":"2021-11-23T16:28:15.341219Z","iopub.execute_input":"2021-11-23T16:28:15.341689Z","iopub.status.idle":"2021-11-23T16:28:17.082565Z","shell.execute_reply.started":"2021-11-23T16:28:15.34165Z","shell.execute_reply":"2021-11-23T16:28:17.080543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = train(new_train_dataset, val_dataset, model=model, epochs=8, batch_size=BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T16:28:21.134923Z","iopub.execute_input":"2021-11-23T16:28:21.13521Z","iopub.status.idle":"2021-11-23T17:04:37.677849Z","shell.execute_reply.started":"2021-11-23T16:28:21.135178Z","shell.execute_reply":"2021-11-23T17:04:37.677134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'Simpsons_eff.pth')\nmodel.load_state_dict(torch.load('Simpsons_eff.pth'))","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:04:48.783743Z","iopub.execute_input":"2021-11-23T17:04:48.784314Z","iopub.status.idle":"2021-11-23T17:04:49.009718Z","shell.execute_reply.started":"2021-11-23T17:04:48.784275Z","shell.execute_reply":"2021-11-23T17:04:49.008787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, acc, val_loss, val_acc = zip(*history)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:04:52.224921Z","iopub.execute_input":"2021-11-23T17:04:52.225534Z","iopub.status.idle":"2021-11-23T17:04:52.229802Z","shell.execute_reply.started":"2021-11-23T17:04:52.225494Z","shell.execute_reply":"2021-11-23T17:04:52.228935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nplt.plot(loss, label=\"train_loss\")\nplt.plot(val_loss, label=\"val_loss\")\nplt.legend(loc='best')\nplt.xlabel(\"epochs\")\nplt.ylabel(\"loss\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:04:53.811697Z","iopub.execute_input":"2021-11-23T17:04:53.811969Z","iopub.status.idle":"2021-11-23T17:04:54.045526Z","shell.execute_reply.started":"2021-11-23T17:04:53.811939Z","shell.execute_reply":"2021-11-23T17:04:54.044726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nplt.plot(acc, label=\"train_acc\")\nplt.plot(val_acc, label=\"val_acc\")\nplt.legend(loc='best')\nplt.xlabel(\"epochs\")\nplt.ylabel(\"acc\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:04:56.607368Z","iopub.execute_input":"2021-11-23T17:04:56.608296Z","iopub.status.idle":"2021-11-23T17:04:56.83048Z","shell.execute_reply.started":"2021-11-23T17:04:56.608246Z","shell.execute_reply":"2021-11-23T17:04:56.829713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. Получение предсказания","metadata":{}},{"cell_type":"code","source":"def predict(model, test_loader):\n    with torch.no_grad(): \n        logits = []\n    \n        for inputs in test_loader:\n            inputs = inputs.to(DEVICE)\n            model.eval()\n            outputs = model(inputs).cpu()\n            logits.append(outputs)\n            \n    probs = nn.functional.softmax(torch.cat(logits), dim=-1).numpy()\n    return probs","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:05:04.451756Z","iopub.execute_input":"2021-11-23T17:05:04.452326Z","iopub.status.idle":"2021-11-23T17:05:04.457799Z","shell.execute_reply.started":"2021-11-23T17:05:04.452288Z","shell.execute_reply":"2021-11-23T17:05:04.456932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_one_sample(model, inputs, device=DEVICE):\n    with torch.no_grad():\n        inputs = inputs.to(device)\n        model.eval()\n        logit = model(inputs).cpu()\n        probs = torch.nn.functional.softmax(logit, dim=-1).numpy()\n    return probs","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:05:06.767145Z","iopub.execute_input":"2021-11-23T17:05:06.767657Z","iopub.status.idle":"2021-11-23T17:05:06.772886Z","shell.execute_reply.started":"2021-11-23T17:05:06.76762Z","shell.execute_reply":"2021-11-23T17:05:06.772061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_characters = int(np.random.uniform(0,1000))\nex_img, true_label = val_dataset[random_characters]\nprobs_im = predict_one_sample(model, ex_img.unsqueeze(0))\n\nidxs = list(map(int, np.random.uniform(0,1000, 20)))\nimgs = [val_dataset[id][0].unsqueeze(0) for id in idxs]\n\nprobs_ims = predict(model, imgs)\n\nlabel_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))\n\ny_pred = np.argmax(probs_ims,-1)\n\nactual_labels = [val_dataset[id][1] for id in idxs]\n\npreds_class = [label_encoder.classes_[i] for i in y_pred]","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:05:09.120778Z","iopub.execute_input":"2021-11-23T17:05:09.121145Z","iopub.status.idle":"2021-11-23T17:05:10.019932Z","shell.execute_reply.started":"2021-11-23T17:05:09.121098Z","shell.execute_reply":"2021-11-23T17:05:10.019139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = SimpsonsDataset(test_files, mode=\"test\")\ntest_loader = DataLoader(test_dataset, shuffle=False, batch_size=64)\nprobs = predict(model, test_loader) #матрица с вероятностями для каждого класса\n\npreds = label_encoder.inverse_transform(np.argmax(probs, axis=1)) #вектор в наибольшими вероятностями\ntest_filenames = [path.name for path in test_dataset.files]","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:05:13.609054Z","iopub.execute_input":"2021-11-23T17:05:13.609735Z","iopub.status.idle":"2021-11-23T17:05:18.613594Z","shell.execute_reply.started":"2021-11-23T17:05:13.609698Z","shell.execute_reply":"2021-11-23T17:05:18.612884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndf = pd.DataFrame()\ndf['Id'] = test_filenames\ndf['Expected'] = preds\ndf.to_csv(Path('./submission_eff!.csv'), index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T17:05:25.868542Z","iopub.execute_input":"2021-11-23T17:05:25.868811Z","iopub.status.idle":"2021-11-23T17:05:25.883022Z","shell.execute_reply.started":"2021-11-23T17:05:25.868781Z","shell.execute_reply":"2021-11-23T17:05:25.882175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Результат на каггле 0.98831","metadata":{}},{"cell_type":"markdown","source":"Также были проведены эксперименты:\n1. Простая сеть CNN с использованием BatchNorm, Dropout. Результат 0.92561\n2. AlexNet с заморозкой всех слоев. Результат 0.83740\n3. AlexNet без заморозки слоев. Результат 0.96918\n3. Inception с заморозкой всех слоев. Результат 0.65143\n4. Inception без заморозки слоев. Результат 0.95430","metadata":{}}]}